{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "import tweepy as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"C:\\Users\\tugno\\OneDrive\\Projects\\Twitter\\Set-up\\keys.txt\"\n",
    "\n",
    "with open(file, 'r') as file:\n",
    "    all_keys = file.read().splitlines()\n",
    "    api_key = all_keys[1]\n",
    "    api_key_secret = all_keys[3]\n",
    "    access_token = all_keys[7]\n",
    "    access_token_secret = all_keys[9]\n",
    "\n",
    "authenticator = tp.OAuthHandler(api_key, api_key_secret)\n",
    "authenticator.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tp.API(authenticator, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credentials are ok\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    api.verify_credentials()\n",
    "    print('Credentials are ok')\n",
    "except:\n",
    "    print('Credentials are NOT ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test for a short tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status(_api=<tweepy.api.API object at 0x00000193D3232860>, _json={'created_at': 'Sat Aug 27 17:10:44 +0000 2022', 'id': 1563574747023421444, 'id_str': '1563574747023421444', 'text': 'This is a test-tweet from the tweepy library #Python', 'truncated': False, 'entities': {'hashtags': [{'text': 'Python', 'indices': [45, 52]}], 'symbols': [], 'user_mentions': [], 'urls': []}, 'source': '<a href=\"https://twitter.com/AlessioTugnoli\" rel=\"nofollow\">bot-tweet-dp203</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'user': {'id': 970607903479648256, 'id_str': '970607903479648256', 'name': 'ðŸ›¸', 'screen_name': 'AlessioTugnoli', 'location': '', 'description': 'Data Scientist | SQL Python Power BI Azure', 'url': 'https://t.co/nLDs9Vh6Uv', 'entities': {'url': {'urls': [{'url': 'https://t.co/nLDs9Vh6Uv', 'expanded_url': 'https://www.linkedin.com/mwlite/in/alessio-tugnoli-97317b223', 'display_url': 'linkedin.com/mwlite/in/alesâ€¦', 'indices': [0, 23]}]}, 'description': {'urls': []}}, 'protected': False, 'followers_count': 16, 'friends_count': 261, 'listed_count': 0, 'created_at': 'Mon Mar 05 10:32:11 +0000 2018', 'favourites_count': 2173, 'utc_offset': None, 'time_zone': None, 'geo_enabled': True, 'verified': False, 'statuses_count': 137, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'F5F8FA', 'profile_background_image_url': None, 'profile_background_image_url_https': None, 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1448493877103669249/TTJID5-e_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1448493877103669249/TTJID5-e_normal.jpg', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/970607903479648256/1634182851', 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': True, 'default_profile': True, 'default_profile_image': False, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none', 'withheld_in_countries': []}, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 0, 'favorite_count': 0, 'favorited': False, 'retweeted': False, 'lang': 'en'}, created_at=datetime.datetime(2022, 8, 27, 17, 10, 44, tzinfo=datetime.timezone.utc), id=1563574747023421444, id_str='1563574747023421444', text='This is a test-tweet from the tweepy library #Python', truncated=False, entities={'hashtags': [{'text': 'Python', 'indices': [45, 52]}], 'symbols': [], 'user_mentions': [], 'urls': []}, source='bot-tweet-dp203', source_url='https://twitter.com/AlessioTugnoli', in_reply_to_status_id=None, in_reply_to_status_id_str=None, in_reply_to_user_id=None, in_reply_to_user_id_str=None, in_reply_to_screen_name=None, author=User(_api=<tweepy.api.API object at 0x00000193D3232860>, _json={'id': 970607903479648256, 'id_str': '970607903479648256', 'name': 'ðŸ›¸', 'screen_name': 'AlessioTugnoli', 'location': '', 'description': 'Data Scientist | SQL Python Power BI Azure', 'url': 'https://t.co/nLDs9Vh6Uv', 'entities': {'url': {'urls': [{'url': 'https://t.co/nLDs9Vh6Uv', 'expanded_url': 'https://www.linkedin.com/mwlite/in/alessio-tugnoli-97317b223', 'display_url': 'linkedin.com/mwlite/in/alesâ€¦', 'indices': [0, 23]}]}, 'description': {'urls': []}}, 'protected': False, 'followers_count': 16, 'friends_count': 261, 'listed_count': 0, 'created_at': 'Mon Mar 05 10:32:11 +0000 2018', 'favourites_count': 2173, 'utc_offset': None, 'time_zone': None, 'geo_enabled': True, 'verified': False, 'statuses_count': 137, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'F5F8FA', 'profile_background_image_url': None, 'profile_background_image_url_https': None, 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1448493877103669249/TTJID5-e_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1448493877103669249/TTJID5-e_normal.jpg', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/970607903479648256/1634182851', 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': True, 'default_profile': True, 'default_profile_image': False, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none', 'withheld_in_countries': []}, id=970607903479648256, id_str='970607903479648256', name='ðŸ›¸', screen_name='AlessioTugnoli', location='', description='Data Scientist | SQL Python Power BI Azure', url='https://t.co/nLDs9Vh6Uv', entities={'url': {'urls': [{'url': 'https://t.co/nLDs9Vh6Uv', 'expanded_url': 'https://www.linkedin.com/mwlite/in/alessio-tugnoli-97317b223', 'display_url': 'linkedin.com/mwlite/in/alesâ€¦', 'indices': [0, 23]}]}, 'description': {'urls': []}}, protected=False, followers_count=16, friends_count=261, listed_count=0, created_at=datetime.datetime(2018, 3, 5, 10, 32, 11, tzinfo=datetime.timezone.utc), favourites_count=2173, utc_offset=None, time_zone=None, geo_enabled=True, verified=False, statuses_count=137, lang=None, contributors_enabled=False, is_translator=False, is_translation_enabled=False, profile_background_color='F5F8FA', profile_background_image_url=None, profile_background_image_url_https=None, profile_background_tile=False, profile_image_url='http://pbs.twimg.com/profile_images/1448493877103669249/TTJID5-e_normal.jpg', profile_image_url_https='https://pbs.twimg.com/profile_images/1448493877103669249/TTJID5-e_normal.jpg', profile_banner_url='https://pbs.twimg.com/profile_banners/970607903479648256/1634182851', profile_link_color='1DA1F2', profile_sidebar_border_color='C0DEED', profile_sidebar_fill_color='DDEEF6', profile_text_color='333333', profile_use_background_image=True, has_extended_profile=True, default_profile=True, default_profile_image=False, following=False, follow_request_sent=False, notifications=False, translator_type='none', withheld_in_countries=[]), user=User(_api=<tweepy.api.API object at 0x00000193D3232860>, _json={'id': 970607903479648256, 'id_str': '970607903479648256', 'name': 'ðŸ›¸', 'screen_name': 'AlessioTugnoli', 'location': '', 'description': 'Data Scientist | SQL Python Power BI Azure', 'url': 'https://t.co/nLDs9Vh6Uv', 'entities': {'url': {'urls': [{'url': 'https://t.co/nLDs9Vh6Uv', 'expanded_url': 'https://www.linkedin.com/mwlite/in/alessio-tugnoli-97317b223', 'display_url': 'linkedin.com/mwlite/in/alesâ€¦', 'indices': [0, 23]}]}, 'description': {'urls': []}}, 'protected': False, 'followers_count': 16, 'friends_count': 261, 'listed_count': 0, 'created_at': 'Mon Mar 05 10:32:11 +0000 2018', 'favourites_count': 2173, 'utc_offset': None, 'time_zone': None, 'geo_enabled': True, 'verified': False, 'statuses_count': 137, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'F5F8FA', 'profile_background_image_url': None, 'profile_background_image_url_https': None, 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1448493877103669249/TTJID5-e_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1448493877103669249/TTJID5-e_normal.jpg', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/970607903479648256/1634182851', 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': True, 'default_profile': True, 'default_profile_image': False, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none', 'withheld_in_countries': []}, id=970607903479648256, id_str='970607903479648256', name='ðŸ›¸', screen_name='AlessioTugnoli', location='', description='Data Scientist | SQL Python Power BI Azure', url='https://t.co/nLDs9Vh6Uv', entities={'url': {'urls': [{'url': 'https://t.co/nLDs9Vh6Uv', 'expanded_url': 'https://www.linkedin.com/mwlite/in/alessio-tugnoli-97317b223', 'display_url': 'linkedin.com/mwlite/in/alesâ€¦', 'indices': [0, 23]}]}, 'description': {'urls': []}}, protected=False, followers_count=16, friends_count=261, listed_count=0, created_at=datetime.datetime(2018, 3, 5, 10, 32, 11, tzinfo=datetime.timezone.utc), favourites_count=2173, utc_offset=None, time_zone=None, geo_enabled=True, verified=False, statuses_count=137, lang=None, contributors_enabled=False, is_translator=False, is_translation_enabled=False, profile_background_color='F5F8FA', profile_background_image_url=None, profile_background_image_url_https=None, profile_background_tile=False, profile_image_url='http://pbs.twimg.com/profile_images/1448493877103669249/TTJID5-e_normal.jpg', profile_image_url_https='https://pbs.twimg.com/profile_images/1448493877103669249/TTJID5-e_normal.jpg', profile_banner_url='https://pbs.twimg.com/profile_banners/970607903479648256/1634182851', profile_link_color='1DA1F2', profile_sidebar_border_color='C0DEED', profile_sidebar_fill_color='DDEEF6', profile_text_color='333333', profile_use_background_image=True, has_extended_profile=True, default_profile=True, default_profile_image=False, following=False, follow_request_sent=False, notifications=False, translator_type='none', withheld_in_countries=[]), geo=None, coordinates=None, place=None, contributors=None, is_quote_status=False, retweet_count=0, favorite_count=0, favorited=False, retweeted=False, lang='en')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.update_status('This is a test-tweet from the tweepy library #Python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test for a thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_tweet = api.update_status('This is the first tweet of a thread.')\n",
    "\n",
    "long_tweet = \"Candidates for this exam should have subject matter expertise integrating, transforming, and consolidating \\\n",
    "     data from various structured and unstructured data systems into a structure that is suitable for building analytics solutions.\"\n",
    "\n",
    "#len(long_tweet)\n",
    "reply_1 = api.update_status(status=long_tweet, in_reply_to_status_id=first_tweet.id, auto_populate_reply_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Candidates for this exam should have subject matter expertise integrating, transforming, and consolidating data from various structured and unstructured data systems into a structure that is suitable for building analytics solutions. \\\n",
    "Azure data engineers help stakeholders understand the data through exploration, and they build and maintain secure and compliant data processing pipelines by using different tools and techniques. These professionals use various Azure data services and languages to store and produce cleansed and enhanced datasets for analysis. \\\n",
    "Azure data engineers also help ensure that data pipelines and data stores are high-performing, efficient, organized, and reliable, given a set of business requirements and constraints. They deal with unanticipated issues swiftly, and they minimize data loss. They also design, implement, monitor, and optimize data platforms to meet the data pipelines needs. \\\n",
    "A candidate for this exam must have strong knowledge of data processing languages such as SQL, Python, or Scala, and they need to understand parallel processing and data architecture patterns.\"\n",
    "\n",
    "#text = \"Candidates for this exam should have subject matter expertise integrating, transforming, and consolidating data from various structured and unstructured data systems into a structure that is suitable for building analytics solutions.\"\n",
    "\n",
    "# number of parts\n",
    "n = ceil(len(text)/280)\n",
    "# number of characters\n",
    "c = 280\n",
    "reply = []\n",
    "for i in range(0, len(text), c):\n",
    "    reply.append(text[i:i+c])\n",
    "\n",
    "#reply\n",
    "\n",
    "first_tweet = api.update_status('This is the first tweet of a thread.')\n",
    "reply_1 = api.update_status(status=reply[0], in_reply_to_status_id=first_tweet.id, auto_populate_reply_metadata=True)\n",
    "reply_2 = api.update_status(status=reply[1], in_reply_to_status_id=reply_1.id, auto_populate_reply_metadata=True)\n",
    "reply_3 = api.update_status(status=reply[2], in_reply_to_status_id=reply_2.id, auto_populate_reply_metadata=True)\n",
    "reply_4 = api.update_status(status=reply[3], in_reply_to_status_id=reply_3.id, auto_populate_reply_metadata=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exec_tweet():\n",
    "\n",
    "\t# empty list for store the partsd of the text --> text is the variable that contains the full thread\n",
    "\treply = []\n",
    "\t# max number of characters for the tweet\n",
    "\tc = 280\n",
    "\tfor i in range(0, len(text), c):\n",
    "\t\treply.append(text[i:i+c])\n",
    "\n",
    "\t# empty list for store the code for each reply of the thread\n",
    "\treply_codes = []\n",
    "\t# parts of the text\n",
    "\tn = ceil(len(text)/280)\n",
    "\n",
    "\tfor t in range(1, n+1):\n",
    "\t\treply_codes.append(f'reply_{t} = api.update_status(status={reply}[{t-1}], in_reply_to_status_id=first_tweet.id, auto_populate_reply_metadata=True)')\n",
    "\t# variable string where all the replays are on a single line\n",
    "\tall_replyies = '\\n'.join(reply_codes)\n",
    "\t\n",
    "\t# execute thoses lines as code, not as strings\n",
    "\texec(all_replyies)\n",
    "\t\n",
    "\n",
    "# first tweet of the thread\n",
    "first_tweet = api.update_status('This is the first tweet of a thread:')\n",
    "# Driver Code\n",
    "exec_tweet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Candidates for ',\n",
       " 'this exam shoul',\n",
       " 'd have subject ',\n",
       " 'matter expertis',\n",
       " 'e integrating, ',\n",
       " 'transforming, a',\n",
       " 'nd consolidatin',\n",
       " 'g data from var',\n",
       " 'ious structured',\n",
       " ' and unstructur',\n",
       " 'ed data systems',\n",
       " ' into a structu',\n",
       " 're that is suit',\n",
       " 'able for buildi',\n",
       " 'ng analytics so',\n",
       " 'lutions.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if the single ringle ends with a letter the entire word has to move to the next reply -> every single reply has to finish with a space (\" \").\n",
    "\n",
    "text = \"Candidates for this exam should have subject matter expertise integrating, transforming, and consolidating data from various structured and unstructured data systems into a structure that is suitable for building analytics solutions.\"\n",
    "\n",
    "# empty list for store the partsd of the text --> text is the variable that contains the full thread\n",
    "tweet = []\n",
    "# max number of characters for the tweet (now I assume the max length of the tweet is 15)\n",
    "c = 15\n",
    "for i in range(0, len(text), c):\n",
    "    tweet.append(text[i:i+c])\n",
    "\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last character is a space\n",
      "Last character is not a space\n",
      "Last character is a space\n",
      "Last character is not a space\n",
      "Last character is a space\n",
      "Last character is not a space\n",
      "Last character is not a space\n",
      "Last character is not a space\n",
      "Last character is not a space\n",
      "Last character is not a space\n",
      "Last character is not a space\n",
      "Last character is not a space\n",
      "Last character is not a space\n",
      "Last character is not a space\n",
      "Last character is not a space\n",
      "Last character is not a space\n"
     ]
    }
   ],
   "source": [
    "for string in tweet:\n",
    "    if string[-1] == ' ':\n",
    "        print(\"Last character is a space\")\n",
    "    else:\n",
    "        print(\"Last character is not a space\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "text = \"Candidates for this exam should have subject matter expertise integrating, transforming, and consolidating data from various structured and unstructured data systems into a structure that is suitable for building analytics solutions. \\\n",
    "Azure data engineers help stakeholders understand the data through exploration, and they build and maintain secure and compliant data processing pipelines by using different tools and techniques. These professionals use various Azure data services and languages to store and produce cleansed and enhanced datasets for analysis. \\\n",
    "Azure data engineers also help ensure that data pipelines and data stores are high-performing, efficient, organized, and reliable, given a set of business requirements and constraints. They deal with unanticipated issues swiftly, and they minimize data loss. They also design, implement, monitor, and optimize data platforms to meet the data pipelines needs. \\\n",
    "A candidate for this exam must have strong knowledge of data processing languages such as SQL, Python, or Scala, and they need to understand parallel processing and data architecture patterns.\"\n",
    "\n",
    "wrap_list = textwrap.wrap(text, width=280, fix_sentence_endings=True)\n",
    "print(len(wrap_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273 is the length of this tweet\n",
      "279 is the length of this tweet\n",
      "276 is the length of this tweet\n",
      "278 is the length of this tweet\n",
      "9 is the length of this tweet\n"
     ]
    }
   ],
   "source": [
    "for element in wrap_list:\n",
    "    print(f\"{len(element)} is the length of this tweet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code generator final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "import textwrap\n",
    "import tweepy as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Candidates for this exam should have subject matter expertise integrating, transforming, and consolidating data from various structured and unstructured data systems into a structure that is suitable for building analytics solutions. \\\n",
    "Azure data engineers help stakeholders understand the data through exploration, and they build and maintain secure and compliant data processing pipelines by using different tools and techniques. These professionals use various Azure data services and languages to store and produce cleansed and enhanced datasets for analysis. \\\n",
    "Azure data engineers also help ensure that data pipelines and data stores are high-performing, efficient, organized, and reliable, given a set of business requirements and constraints. They deal with unanticipated issues swiftly, and they minimize data loss. They also design, implement, monitor, and optimize data platforms to meet the data pipelines needs. \\\n",
    "A candidate for this exam must have strong knowledge of data processing languages such as SQL, Python, or Scala, and they need to understand parallel processing and data architecture patterns.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exec_tweet():\n",
    "\n",
    "\t# list wehre there are the parts of the text -> (every single reply to the previous tweet)\n",
    "\treply = textwrap.wrap(text, width=280, fix_sentence_endings=True)\n",
    "\n",
    "\t# empty list for store the code for each reply of the thread\n",
    "\treply_codes = []\n",
    "\t# parts of the text\n",
    "\tn = len(reply)\n",
    "\n",
    "\tfor t in range(0, n+1):\n",
    "\t\treply_codes.append(f'tweet{t+1} = api.update_status(status={reply}[{t}], in_reply_to_status_id=tweet{t}.id, auto_populate_reply_metadata=True)')\n",
    "\t# variable string where all the replays are on a single line\n",
    "\tall_replyies = '\\n'.join(reply_codes)\n",
    "\n",
    "\t# first tweet of the thread\n",
    "\ttweet0 = api.update_status('This is the first tweet of a thread:')\n",
    "\t# execute thoses lines as code, not as strings\n",
    "\texec(all_replyies)\n",
    "\t\n",
    "\n",
    "\n",
    "# Driver Code\n",
    "exec_tweet()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
